# spark_memory_dynamic_allocation

## 项目背景
虽然从 Spark UI 中可以看到 Spark 任务的 Metric，知道内存分配是否合理，从而在下次任务执行前调整运行配置，但是如果任务非常多，
周期执行，每次数据量和内容都有变动，通过观察 Spark UI 手动调整内存工作量非常大甚至是不可完成。

## 项目目标
通过代码埋点，在 Spark 任务执行结束时，将每个 Executor 每个 Stage 使用的峰值内存保留到某个位置，如文件系统或数据库，下次任务执行时
根据上次任务记录的 Metric，动态调整此次任务需要分配的内存大小